# ========================================
# HAMO+ â€” Healthcare AutoML Optimizer Plus
# ========================================
# AutoML for Healthcare Data (Auto-sklearn based)
# Google Colab-ready notebook

# STEP 1: Install dependencies (Colab)
!pip install -q auto-sklearn

# STEP 2: Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    confusion_matrix,
    RocCurveDisplay
)
import autosklearn.classification
import joblib  # For model persistence (optional)

# STEP 3: Generate or load healthcare dataset
def generate_synthetic_healthcare_data(n_samples=3000, seed=42):
    np.random.seed(seed)
    df = pd.DataFrame({
        'age': np.random.randint(20, 90, n_samples),
        'num_prior_admissions': np.random.poisson(1.5, n_samples),
        'length_of_stay': np.random.randint(1, 20, n_samples),
        'num_comorbidities': np.random.randint(0, 5, n_samples),
        'discharge_disposition': np.random.choice([0, 1, 2], n_samples),
        'num_medications': np.random.randint(1, 15, n_samples),
        'lab_result_abnormal_flag': np.random.choice([0, 1], n_samples),
        'previous_readmission': np.random.choice([0, 1], n_samples)
    })

    def generate_target(row):
        score = 0
        score += (row['num_prior_admissions'] > 2) * 1.5
        score += (row['length_of_stay'] > 7) * 1.0
        score += (row['num_comorbidities'] > 2) * 1.2
        score += (row['discharge_disposition'] == 1) * 0.8
        score += row['previous_readmission'] * 2.0
        score += row['lab_result_abnormal_flag'] * 0.7
        prob = 1 / (1 + np.exp(-score))
        return np.random.rand() < prob

    df['readmitted_30days'] = df.apply(generate_target, axis=1).astype(int)
    return df

# Uncomment below and load your real dataset if available
# data = pd.read_csv("your_healthcare_data.csv")
data = generate_synthetic_healthcare_data()

# STEP 4: Prepare features and target
X = data.drop(columns=['readmitted_30days'])
y = data['readmitted_30days']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# STEP 5: Train AutoML model
automl = autosklearn.classification.AutoSklearnClassifier(
    time_left_for_this_task=300,
    per_run_time_limit=30,
    ensemble_size=50,
    seed=42,
    n_jobs=-1,
    memory_limit=4096
)

print("â³ Training AutoML model... This will take a few minutes.")
automl.fit(X_train, y_train)

print("\nâœ… Training Complete. Final Ensemble:")
print(automl.show_models())

# STEP 6: Make predictions
y_pred = automl.predict(X_test)
y_proba = automl.predict_proba(X_test)[:, 1]

# STEP 7: Evaluation metrics
print("\nðŸ“Š Classification Report:")
print(classification_report(y_test, y_pred))

print(f"ðŸŽ¯ ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}")

print("ðŸ“‰ Confusion Matrix:")
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# STEP 8: ROC Curve
RocCurveDisplay.from_predictions(y_test, y_proba)
plt.title("ROC Curve")
plt.grid()
plt.show()

# STEP 9: (Optional) Save model to file
# joblib.dump(automl, "HAMO_model.pkl")
